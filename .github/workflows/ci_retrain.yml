# .github/workflows/ci_retrain.yml

name: CI - Retrain ML Model

on:
  push:
    branches:
      - main 
    paths:
      - 'MLProject/modelling_tuning.py'
      - 'MLProject/conda.yaml'
      - 'MLProject/MLProject'
      - 'MLProject/requirements.txt'
      - 'MLProject/telco_churn_preprocessing/**'
  workflow_dispatch:

jobs:
  retrain_model:
    runs-on: ubuntu-latest

    permissions:
      contents: write
      id-token: write

    env:
      DAGSHUB_REPO_NAME: CI-Workflow
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Conda Environment
      uses: conda-incubator/setup-miniconda@v2
      with:
          python-version: 3.9
          auto-activate-base: true
          activate-environment: mlproject-env
          environment-file: MLProject/conda.yaml

    - name: Install MLflow and DagsHub client
      run: |
        source "$(conda info --base)/etc/profile.d/conda.sh"
        conda activate mlproject-env
        
        python -m pip install --upgrade pip
        pip install mlflow==2.13.0 dagshub==0.5.10

        python -c "import dagshub; print('DagsHub version:', dagshub.__version__)"
        python -c "import mlflow; print('MLflow version:', mlflow.__version__)"

    - name: Configure DagsHub MLflow Tracking
      run: |
        echo "MLFLOW_TRACKING_URI=https://dagshub.com/hyrahmaaa/Workflow-CI.mlflow" >> "$GITHUB_ENV"
        echo "MLFLOW_TRACKING_USERNAME=hyrahmaaa" >> "$GITHUB_ENV"
        echo "MLFLOW_TRACKING_PASSWORD=${{ secrets.DAGSHUB_TOKEN }}" >> "$GITHUB_ENV"
        echo "DAGSHUB_REPO_NAME=${{ github.event.repository.name }}" >> "$GITHUB_ENV"

    - name: Run MLflow Project (Model Retraining)
      id: run_mlflow_project
      run: |
        set -e
        source "$(conda info --base)/etc/profile.d/conda.sh"
        conda activate mlproject-env
        
        echo "=== Executing mlflow run MLProject/ Directly ==="
        MLFLOW_FULL_OUTPUT=$(mlflow run MLProject/ 2>&1)
        echo "$MLFLOW_FULL_OUTPUT"

        RUN_ID=$(echo "$MLFLOW_FULL_OUTPUT" | grep -oP "run with ID '\K[^']+" | tail -n 1)
        
        if [ -z "$RUN_ID" ]; then
          echo "Error: MLflow Run ID could not be extracted. MLflow run might have failed."
          exit 1
        fi
        
        echo "MLFLOW_RUN_ID=$RUN_ID" >> "$GITHUB_ENV"
        echo "MLflow run initiated with ID: $RUN_ID"
        echo "mlflow_run_id=$RUN_ID" >> "$GITHUB_OUTPUT"
        
        echo "=== mlflow run command finished ==="
      env:
        MLFLOW_TRACKING_URI: ${{ env.MLFLOW_TRACKING_URI }}
        MLFLOW_TRACKING_USERNAME: ${{ env.MLFLOW_TRACKING_USERNAME }}
        MLFLOW_TRACKING_PASSWORD: ${{ env.MLFLOW_TRACKING_PASSWORD }}

    - name: Download Model Artifact for Further Use
      run: |
        set -e
        source "$(conda info --base)/etc/profile.d/conda.sh"
        conda activate mlproject-env
        
        MLFLOW_RUN_ID="${{ steps.run_mlflow_project.outputs.mlflow_run_id }}"
        
        if [ -z "$MLFLOW_RUN_ID" ]; then
          echo "Error: MLFLOW_RUN_ID is empty. Cannot download artifact."
          exit 1
        fi
        
        echo "Attempting to download artifact for run ID '$MLFLOW_RUN_ID' from DagsHub..."
        
        python -c "
import mlflow
import os
import shutil 

# Set MLflow configuration
mlflow.set_tracking_uri(os.environ.get('MLFLOW_TRACKING_URI_GHA'))

# Get environment variables
run_id = os.environ.get('MLFLOW_RUN_ID_GHA')
artifact_path_on_dagshub = os.environ.get('ARTIFACT_NAME_ON_DAGSHUB_GHA')
download_destination = os.environ.get('DOWNLOAD_DESTINATION_GHA')

print(f'Configuration:')
print(f'  MLflow URI: {os.environ.get(\"MLFLOW_TRACKING_URI_GHA\")}')
print(f'  Run ID: {run_id}')
print(f'  Artifact path: {artifact_path_on_dagshub}')
print(f'  Download destination: {download_destination}')

# Validate inputs
if not run_id:
    raise ValueError('MLFLOW_RUN_ID_GHA is empty')
if not artifact_path_on_dagshub:
    raise ValueError('ARTIFACT_NAME_ON_DAGSHUB_GHA is empty')
if not download_destination:
    raise ValueError('DOWNLOAD_DESTINATION_GHA is empty')

# Create download destination directory if it doesn't exist
os.makedirs(os.path.dirname(download_destination), exist_ok=True)

# Clean existing directory if it exists
if os.path.exists(download_destination):
    print(f'Cleaning existing directory: {download_destination}')
    shutil.rmtree(download_destination)

try:
    # Download artifact
    print(f'Downloading artifact...')
    downloaded_path = mlflow.artifacts.download_artifacts(
        run_id=run_id,
        artifact_path=artifact_path_on_dagshub,
        dst_path=os.path.dirname(download_destination)
    )
    print(f'Artifact successfully downloaded to: {downloaded_path}')
    
    # Validate download
    if not os.path.exists(downloaded_path):
        raise FileNotFoundError(f'Downloaded artifact path does not exist: {downloaded_path}')
    
    # Check if it's a directory or file
    if os.path.isdir(downloaded_path):
        if not os.listdir(downloaded_path):
            raise ValueError(f'Downloaded artifact directory is empty: {downloaded_path}')
        print(f'Downloaded directory contains: {os.listdir(downloaded_path)}')
    else:
        print(f'Downloaded file size: {os.path.getsize(downloaded_path)} bytes')
    
    print('Artifact download completed successfully!')
    
except Exception as e:
    print(f'Error downloading artifact: {str(e)}')
    # Try to list available artifacts for debugging
    try:
        client = mlflow.tracking.MlflowClient()
        artifacts = client.list_artifacts(run_id)
        print(f'Available artifacts for run {run_id}:')
        for artifact in artifacts:
            print(f'  - {artifact.path}')
    except Exception as list_error:
        print(f'Could not list artifacts: {str(list_error)}')
    raise
"
      env:
        MLFLOW_RUN_ID_GHA: ${{ steps.run_mlflow_project.outputs.mlflow_run_id }}
        ARTIFACT_NAME_ON_DAGSHUB_GHA: best_logistic_regression_model_artifact
        DOWNLOAD_DESTINATION_GHA: MLProject/best_logistic_regression_model_artifact
        MLFLOW_TRACKING_URI_GHA: ${{ env.MLFLOW_TRACKING_URI }}
        MLFLOW_TRACKING_USERNAME_GHA: ${{ env.MLFLOW_TRACKING_USERNAME }}
        MLFLOW_TRACKING_PASSWORD_GHA: ${{ secrets.DAGSHUB_TOKEN }}
      if: success() && steps.run_mlflow_project.outputs.mlflow_run_id != ''
      
    - name: Commit processed data
      run: |
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git pull origin main --rebase
        git add .
        git commit -m "Automated: Model retraining results and artifacts updated" || true
        git push
